import React, { Component } from 'react';
import '../styles/blogTemplate.css';

export default class Designjustice extends Component {
  render() {
    return (
      <article className='blogBody'>
        <section className='leftSide'>
        this is an image
        </section>
        <section className='rightSide'>
<h1>
  Design Justice 
</h1>
<time> 12 December 200</time>
<p>
  Technology is often categorized as a progressive field that subverts the norms of the society but often, the injustice that is embedded in the sector is overlooked.  The role of sexism in the tech industry is a powerful one. 

</p>
<p>
There is often a preconceived notion of what it means to be a technologist, often times taking on the identity of the cishet white men who are credited with pioneering the field as people like Bill Gates and Mark Zuckerberg become the faces of the industry. This identity attached to development is largely exclusionary. This has led to a lack of female and non-binary individuals in the technology industry.
</p>
<p>
Constanta-Chock 2020 pp 6 outlines design justice principles to highlight the issues within the industry. This includes redressing the problems of ignoring marginalized communities, shifting the focus from the intention of code to the impact of code, and providing voices in the tech space to previously marginalized groups. This is a beautiful start and needed transformation in the industry but the problem has much deeper roots than an isolated field. 

</p>
<p>
  Kilbourne and Weeks 2002 highlight that the cause of <q>patriarchal technology</q> is directly influenced by the epistemological systems that rule western societies. As South Africans, we fall into this being a previously colonize state that has adopted European ideals. Kilbourne and Weeks argue that traditional market economics has provided the foundation for the technology industry to be created and serve a male population primarily.

</p>
<p>
  The technology design is based on ideas that tend to be reductionist to humans. This can be seen in the use of the female automata. The presence of female identity in technology is clearly based on domesticated ideals. One can easily identify the idea of what women represent in the technological space by investigating the darker underbelly of popular virtual assistants such as Siri and Amazons Alexa Adams 2020. These task managers are primarily female and take on the role of serving the user, making the experience more convenient and ultimately reinforcing the subservient female role. The idea of stereotypes finding a way into technology can also be seen in the bias seen in Natural Language Processing. NLP is a form of machine learning and uses words to train the algorithm. The gender bias in NLP is derivative of the gender bias Lu et al, 2020 
that exists in the language we speak. The data given to train the models are already biased because our day-to-day conversations are plagued with biases created over centuries. 

</p>
<p>
  This illustrates that while we make an effort to reform an industry, the issue exists at all levels of society. Many of our biases and internalized misogyny are so deep-rooted, that a complete restart of the institutions that govern contemporary life is needed to eradicate injustice. This begs the question: “how do we become ethical and unbiased technologists?”. I believe that the start to seeing a more inclusive field is for more developers and designers to be conscious of the incredible gender, race, and locational inequality that exists within technology.

</p>
        </section>
        <ul className='refList'>
<li>Adams, R. 2020. Helen ALoy and other tales of female automata: a gendered reading of the narratives of hopes and fears of intelligent machines and artificial intelligence. AI and SOCIETY 35, pp. 56 579. doi: 10.1007/s00146-019-00918-7. Viewed 27 March 2022 </li>
<li>Costanza-Chock, S. 2020. Design Justice: Community-Led Practices to Build the Worlds We Need. The MIT Press. Available at: https://library.oapen.org/handle/20.500.12657/43542 Accessed: 27 June 2022.</li>
   <li>
         Kilbourne, W. and Weeks, S. 2002. A socio-economic perspective on gender bias in technology. The Journal of Socio-Economics 26, pp. 243to260. doi: 10.1016/S1053-535790018-4.
          </li>
          <li>
        
Lu, K. et al. 2020. Gender Bias in Neural Natural Language Processing. In: Nigam, V. et al. eds. Logic, Language, and Security: Essays Dedicated to Andre Scedrov on the Occasion of His 65th Birthday. Lecture Notes in Computer Science. Cham: Springer International Publishing, pp. 189.202. Available at: https://doi.org/10.1007/978-3-030-62077-6_14 [Accessed: 27 June 2022]
          </li>
        </ul>
      </article>
    )
  }
}
